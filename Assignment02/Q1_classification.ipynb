{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import datasets,svm,tree, metrics\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(fileName):\n",
    "    dataset = pd.read_table(fileName, header=0, sep=\",\", encoding=\"unicode_escape\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess creates the term frequency matrix for the review data set\n",
    "def preprocess(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    data = count_vectorizer.fit_transform(data)\n",
    "    \n",
    "    #tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(data,target):\n",
    "    classifier = None\n",
    "    #Split the Dataset according to the Classes\n",
    "    Array = data.toarray()\n",
    "    array_row,array_col = Array.shape\n",
    "    Classes = list(np.unique(target))\n",
    "    A_given_C = np.zeros((len(Classes),array_col))\n",
    "    Probability = [0]*len(Classes)\n",
    "\n",
    "    for index  in range(len(Classes)):\n",
    "        temp = Array[target == Classes[index]]\n",
    "        class_row,class_col = temp.shape\n",
    "        A_given_C[index] = np.sum(temp,axis=0)\n",
    "        A_given_C[index]+=1\n",
    "        Sum_A_given_C = np.sum(A_given_C[index])\n",
    "        A_given_C[index] = A_given_C[index]/Sum_A_given_C\n",
    "        Probability[index] = class_row/array_row\n",
    "    Class_Probability = pd.Series(Probability,Classes)\n",
    "\n",
    "    classifier = (A_given_C,Class_Probability,Classes)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(classifier, testdata):\n",
    "    predicted_val=[]\n",
    "    A_given_C = classifier[0]\n",
    "    Class_Probability = classifier[1]\n",
    "    Classes = classifier[2]\n",
    "    TestArray = testdata.toarray()\n",
    "    \n",
    "    ArrayRow,ArrayCol = TestArray.shape\n",
    "    for i in range(ArrayRow): # ArrayRow\n",
    "        temp_values = [0]*len(Classes)\n",
    "        for j in range(len(Classes)):\n",
    "            temp_values[j] = Class_Probability[Classes[j]]*A_given_C[j][TestArray[i].astype(bool)].prod()\n",
    "        temp_series = pd.Series(temp_values,Classes)\n",
    "        predicted_val.append(temp_series.idxmax())\n",
    "  \n",
    "    return predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(actual_class, predicted_class):\n",
    "    accuracy = -1    \n",
    "    #Your code to evaluate the model will go here. The code will print overall model's accuracy  and precision \n",
    "    #and recall for each class label.\n",
    "    \n",
    "    Classes = list(np.unique(actual_class))\n",
    "    print(\"The Class Labels : \")\n",
    "    print(Classes)\n",
    "    ConfusionMatrix = np.zeros((len(Classes),len(Classes)))\n",
    "    Series_Class = pd.Series([i for i in range(len(Classes))],Classes)\n",
    "    Act_Predict_Dict  = {\"Actual\":actual_class,\"Predicted\":predicted_class}\n",
    "    Act_Predict_df = pd.DataFrame(Act_Predict_Dict)\n",
    "    for actual in Classes:\n",
    "        for predict in Classes:\n",
    "            ConfusionMatrix[Series_Class[actual]][Series_Class[predict]]=int(np.sum(np.logical_and(Act_Predict_df['Actual']==actual,Act_Predict_df['Predicted']==predict))) \n",
    "    print(\"The confusion matrix : \")\n",
    "    print(ConfusionMatrix.astype(int))\n",
    "    precision = np.sum(np.diag(ConfusionMatrix)) / np.sum(np.sum(ConfusionMatrix, axis = 0))     \n",
    "    accuracy = np.sum([actual_class == predicted_class]) / len(actual_class)\n",
    "    recall =np.diag(ConfusionMatrix)/ np.sum(ConfusionMatrix,axis=1)\n",
    "\n",
    "    print(\"The accuracy score is :\",accuracy)\n",
    "    print(\"The precision score is :\",precision)\n",
    "    print(\"The recall score for each class label is : \",recall)\n",
    "    # Refrence : https://www.youtube.com/watch?v=FAr2GmWNbT0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data.....\n",
      "preprocessing data.....\n",
      "Learning model.....\n",
      "Classifying test data......\n",
      "Evaluating results.....\n",
      "The Class Labels : \n",
      "['APPOINTMENTS', 'ASK_A_DOCTOR', 'JUNK', 'LAB', 'MISCELLANEOUS', 'PRESCRIPTION']\n",
      "The confusion matrix : \n",
      "[[4196  421    0   72  478  442]\n",
      " [ 320 2912    0  100  631  678]\n",
      " [   0    0    0    0    9    1]\n",
      " [ 115  135    0 1085  289  105]\n",
      " [ 343  425    0  102 3044  969]\n",
      " [ 158  394    0  105  471 4912]]\n",
      "The accuracy score is : 0.7048271648044693\n",
      "The precision score is : 0.7048271648044693\n",
      "The recall score for each class label is :  [0.74808344 0.62745098 0.         0.62753036 0.62338726 0.81324503]\n"
     ]
    }
   ],
   "source": [
    "features = [\"SUMMARY\", \"categories\", \"sub_categories\"]\n",
    "\n",
    "print(\"Loading data.....\")\n",
    "dataset = load_file(\"TextClassification_Data.csv\")\n",
    "data,target = dataset[features[0]].fillna(\" \"), dataset[features[1]]\n",
    "\n",
    "print(\"preprocessing data.....\")\n",
    "word_vectors = preprocess(data)\n",
    "    \n",
    "trainingX,testX,trainingY,testY = train_test_split(word_vectors,target,test_size=0.4,random_state=43)\n",
    "\n",
    "print(\"Learning model.....\")\n",
    "# classifier = BernoulliNB()\n",
    "# classifier.fit(trainingX,trainingY)\n",
    "\n",
    "model = learn_model(trainingX,trainingY)\n",
    "\n",
    "print(\"Classifying test data......\") \n",
    "#predictedY = classifier.predict(testX)     \n",
    "predictedY = classify(model, testX)\n",
    "\n",
    "print(\"Evaluating results.....\")\n",
    "evaluate(testY,predictedY)\n",
    "# print(metrics.accuracy_score(testY,predictedY))\n",
    "# print(metrics.recall_score(predictedY, testY,average = 'micro'))\n",
    "# print(metrics.precision_score(predictedY, testY,average = 'micro'))\n",
    "# print(metrics.f1_score(predictedY,testY,average = 'micro'))\n",
    "# #print(np.mean(metrics.precision_score(predictedY, testY,average = None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}